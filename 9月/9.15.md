## 学工程化时产生的疑问：有了 babel 为啥还需要 corejs?

1. Babel 的作用
Babel 的核心功能是 语法转换 (Syntax Transform)
比如：

// 源码 (ES6)
const fn = () => [1, 2, 3].includes(2);

// Babel 转换后的 ES5
var fn = function fn() {
  return [1, 2, 3].includes(2); // 注意：includes 没被改写！
};
👉 可以看到，Babel 只把 箭头函数 转换成了普通函数，但 Array.prototype.includes 这个新方法并没有处理。

为什么？
因为 Babel 主要解决的是“新语法 → 旧语法”，但 API/内置对象的功能 它不会自动模拟。

2. core-js 的作用
core-js 提供了 polyfill，也就是对新 API 的“补丁”。
比如：

Promise
Array.prototype.includes
Object.fromEntries
String.prototype.padStart
async/await 背后的 regenerator-runtime
如果你目标环境不支持这些 API，就需要 core-js 来“垫片”，让老环境也能运行。

import "core-js/stable";
import "regenerator-runtime/runtime";
这样 Babel 在编译时就能按需引入 polyfill。

3. 为什么不能只靠 Babel？
举个例子：假设你写了这样的代码

[1, 2, 3].includes(2);
只有 Babel：它不会改写 includes → 老浏览器（IE11）会直接报错 "Object doesn't support property or method 'includes'"。
Babel + core-js：会自动注入 polyfill，老浏览器也能正常运行。
4. 什么时候需要 core-js？
✅ 需要：

你要支持老浏览器（IE/旧版 Chrome/旧版 Safari）
你代码里用到了 ES6+ 的 API（Promise、includes、flat、Object.values 等）
❌ 不需要：

你的代码只跑在 Node.js 新版本（比如 Node 18+）
运行环境天然支持 ES6+ API（比如现代浏览器）
5. 总结一句
Babel：负责把新语法转成旧语法
core-js：负责补上旧环境缺少的 API
👉 没有 core-js，代码“看起来能编译”，但在老环境里会直接报错。

## HMR 和 整页刷新的区别
1. HMR（Hot Module Replacement，热更新）
定义
HMR 是 webpack / Vite 等构建工具提供的一种 只替换变化模块的更新机制。
当你修改代码时，打包工具只重新编译改动的模块，并通过 WebSocket 通知浏览器替换掉对应模块，而不是刷新整个页面。
特点
只更新局部：比如你改了一个 CSS 文件，页面样式会立即更新，但 JS 状态（如表单内容、Redux store、Vue 组件状态）保持不变。
速度快：因为只替换小片段，不用整个页面重新加载。
开发体验好：保持运行中的状态，不会因为刷新而丢失。
使用场景
改样式（CSS/SCSS）
改前端逻辑（React/Vue 组件）
UI 调试
2. WebSocket + 浏览器整页刷新
定义
一些简单的开发服务器（比如最原始的 live-server，或者早期 gulp 插件）会用 WebSocket 来监听文件变化。
一旦文件变动，就通过 WebSocket 发消息给浏览器，让浏览器执行 整页刷新（window.location.reload）。
特点
刷新整个页面：所有资源（HTML、CSS、JS）都会重新加载。
状态丢失：页面里的状态（输入框、全局变量、应用状态）会全部清空。
效率低：即使只改了一行样式，也要整个页面刷新。
使用场景
静态站点开发（HTML/CSS）
不支持模块化热替换的项目

## File Fingerprint
 ### 📌 文件指纹的定义
文件指纹是给静态资源文件（如 JS、CSS、图片等）的文件名加上一个 hash 值，用来标识文件内容是否发生变化。

例如：

没加指纹：app.js
加了指纹：app.98d3f2a.js
这里的 98d3f2a 就是 文件指纹，通常是根据文件内容生成的 MD5/SHA 哈希。

 ### 📋 文件指纹的作用
缓存控制

浏览器会缓存静态资源（JS/CSS/图片），但是如果文件名不变，浏览器可能继续用旧缓存。
加了指纹后，只要文件内容有变化，hash 就会变，文件名随之变化，浏览器就会请求新文件。
如果文件没变，文件名不变，浏览器继续用缓存，减少请求。
避免覆盖问题

多个版本的资源可以同时存在（因为文件名不同），避免 CDN 或服务器缓存冲突。
性能优化

提升缓存命中率（不变的文件长期缓存）
减少用户重复下载资源
 ### 🔑 常见的文件指纹类型
Hash（项目级 hash）

每次构建都会生成新的 hash，哪怕只改一个文件，所有文件 hash 都会变。
缺点：缓存利用率低。
Chunkhash（按入口/模块计算 hash）

只要某个入口的内容没变，它对应的 hash 就不会变。
常用于 JS 文件。
Contenthash（按文件内容计算 hash）

每个文件独立计算 hash，只有内容变了才会变。
最精准，适合 CSS、图片等静态资源。
 ### 📋 举例
Webpack 配置里：

output: {
  filename: '[name].[contenthash:8].js',
  path: path.resolve(__dirname, 'dist')
}
生成的文件可能是：

main.a1b2c3d4.js
vendor.9f8e7d6c.js
style.88cc11aa.css
如果你只改了样式，那么只有 style.88cc11aa.css 的 hash 会变，JS 文件 hash 不会变，浏览器还能继续用缓存的 JS。
 ### ✅ 总结
文件指纹 = 文件名中的哈希标识

本质：根据文件内容生成的唯一“身份证号”
作用：解决 浏览器缓存更新 问题，同时提升缓存利用率
常见形式：[hash]、[chunkhash]、[contenthash]

##  Mastodon 去中心化带来的结果
### 📌 1. 为什么数据不同步？
Mastodon 的每个实例（服务器）都是独立运行的：

用户 A 在 mastodon.social 发了一条嘟文
用户 B 在 fosstodon.org 也能看到，但前提是这两个实例之间有过交互（订阅/关注）
如果两个实例从未互通，B 的服务器就不会存储 A 的内容
👉 所以没有一个“全局统一数据库”，每个人的数据都存放在自己所在的服务器，部分数据会按需同步。

### 📌 2. 去中心化的优点
抗审查

没有单一的公司（如 Twitter/X）能控制整个网络
如果某个实例关停或被封锁，用户可以转移到另一个实例
多样性与自治

不同社区可以有不同的规则和文化
有些实例专注技术，有些专注艺术，有些严格审核，有些自由开放
隐私和所有权

你的数据由你选择的服务器管理，而不是全都交给大公司
一些实例甚至允许你导出、迁移账户
健壮性

单个服务器挂掉不会让整个网络瘫痪
### 📌 3. 去中心化的缺点
数据碎片化

没有全局视图，不像 Twitter 那样“全量内容都能搜”
搜索、推荐的体验会比中心化平台差
上手门槛高

新用户需要先“挑实例”，但往往不明白差别
有些实例小而冷清，用户容易迷路
用户体验不一致

不同实例的管理员政策、性能、功能可能不一样
有的实例更新快，有的可能落后
互操作复杂

实例之间同步可能有延迟
如果某个实例选择“封锁”另一个实例，两边的用户就互相看不到
### 📋 总结
去中心化的本质：每个实例自己管自己，互相通过协议沟通，没有统一的数据库。
结果：每个人的数据不同步，全局体验不像 Twitter 那样“一站式完整”。
优点：抗审查、多样性、用户自治、健壮性。
缺点：数据碎片化、上手复杂、体验不一致、互通有延迟。